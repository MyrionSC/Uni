{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90051 Workshop 8\n",
    "## Ensemble Learning\n",
    "***\n",
    "In this worksheet, we experiment with two ensemble learning algorithms: the Random Forest and Gradient Tree Boosting.\n",
    "By the end of this worksheet, you should:\n",
    "* be able to implement bootstrap aggregation (a.k.a. 'bagging'), particularly as applied to Random Forests; and\n",
    "* be aware of Gradient Tree Boosting, and the features available in the scikit-learn implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data set\n",
    "We'll experiment with the \"Bank Marketing\" data set from the [UCI Machine Learning repository](https://archive.ics.uci.edu/ml/index.php).\n",
    "\n",
    "The data contains records for 45,211 telemarketing customer interactions at a Portuguese bank.\n",
    "The goal is to predict whether the customer will sign up for the product—i.e. a binary classification task.\n",
    "There are 16 mixed (categorical/numeric) features for each customer interaction.\n",
    "Further details are provided [here](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing).\n",
    "\n",
    "The code block below downloads the data from the repository, unzips it, and reads the full CSV file into a `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "\n",
    "resp = urlopen('https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip')\n",
    "zipfile = ZipFile(BytesIO(resp.read()))\n",
    "\n",
    "df = pd.read_csv(zipfile.open('bank-full.csv'), header=0, sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that several features are categorical.\n",
    "This is a problem, since the tree-based learners in `sklearn` don't support categorical features.\n",
    "We must therefore apply feature encoding.\n",
    "\n",
    "A straightforward solution is to apply the `pandas.get_dummies` function to one-hot encode all of the categorical columns in the DataFrame.\n",
    "We then cast the result to a NumPy array called `X`.\n",
    "Notice that we exclude the target variable, which is stored in column `y`.\n",
    "\n",
    "We also re-encode the target variable—`0` for 'no' and `1` for 'yes'—and cast to a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>...</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>2143</td>\n",
       "      <td>5</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1506</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  balance  day  duration  campaign  pdays  previous  job_admin.  \\\n",
       "0   58     2143    5       261         1     -1         0           0   \n",
       "1   44       29    5       151         1     -1         0           0   \n",
       "2   33        2    5        76         1     -1         0           0   \n",
       "3   47     1506    5        92         1     -1         0           0   \n",
       "4   33        1    5       198         1     -1         0           0   \n",
       "\n",
       "   job_blue-collar  job_entrepreneur        ...         month_jun  month_mar  \\\n",
       "0                0                 0        ...                 0          0   \n",
       "1                0                 0        ...                 0          0   \n",
       "2                0                 1        ...                 0          0   \n",
       "3                1                 0        ...                 0          0   \n",
       "4                0                 0        ...                 0          0   \n",
       "\n",
       "   month_may  month_nov  month_oct  month_sep  poutcome_failure  \\\n",
       "0          1          0          0          0                 0   \n",
       "1          1          0          0          0                 0   \n",
       "2          1          0          0          0                 0   \n",
       "3          1          0          0          0                 0   \n",
       "4          1          0          0          0                 0   \n",
       "\n",
       "   poutcome_other  poutcome_success  poutcome_unknown  \n",
       "0               0                 0                 1  \n",
       "1               0                 0                 1  \n",
       "2               0                 0                 1  \n",
       "3               0                 0                 1  \n",
       "4               0                 0                 1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed = pd.get_dummies(df.drop('y', axis=1))\n",
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous',\n",
       "       'job_admin.', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
       "       'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
       "       'job_student', 'job_technician', 'job_unemployed', 'job_unknown',\n",
       "       'marital_divorced', 'marital_married', 'marital_single',\n",
       "       'education_primary', 'education_secondary', 'education_tertiary',\n",
       "       'education_unknown', 'default_no', 'default_yes', 'housing_no',\n",
       "       'housing_yes', 'loan_no', 'loan_yes', 'contact_cellular',\n",
       "       'contact_telephone', 'contact_unknown', 'month_apr', 'month_aug',\n",
       "       'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun',\n",
       "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
       "       'poutcome_failure', 'poutcome_other', 'poutcome_success',\n",
       "       'poutcome_unknown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_transformed.values\n",
    "Y = df.y.map({'no':0, 'yes':1}).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Can you identify any issues with the feature encoding? (Hint: look at `df_transformed.columns`)\n",
    "\n",
    "**Question:** Are the classes balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True, False, False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we partition the data into train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implementation of Random Forest\n",
    "In this section, we'll implement a Random Forest using `sklearn.tree.DecisionTreeClassifier` as the base learner.\n",
    "\n",
    "The pseudo-code for the Random Forest training algorithm is as follows:\n",
    "```\n",
    "Parameters: n_trees (number of trees); max_features (size of random feature subset)\n",
    "Initialise empty forest.\n",
    "While size of forest is less than n_trees:\n",
    "    Create a bootstrap sample from the training data.\n",
    "    Train a decision tree on the sample (with max_features randomly-selected features available for each split).\n",
    "    Add tree to forest.\n",
    "```\n",
    "\n",
    "**Question:** How does this algorithm differ to the one presented in lectures?\n",
    "\n",
    "**Question:** Why are we using random subsets of features?\n",
    "\n",
    "Complete the following code block, with reference to the pseudo-code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_forest(X, Y, n_trees, **kwargs):\n",
    "    \"\"\"\n",
    "    Fit a Random Forest\n",
    "    \n",
    "    Arguments\n",
    "    =========\n",
    "    X : numpy array, shape: (n_instances, n_features)\n",
    "        feature matrix\n",
    "    Y : numpy array, shape (n_instances,)\n",
    "    n_trees : int\n",
    "        number of trees in the forest\n",
    "    *kwargs : keyword arguments passed to DecisionTreeClassifier\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    a dictionary with two keys:\n",
    "      'forest' : list of DecisionTreeClassifier instances\n",
    "      'oob_score' : the out-of-bag accuracy\n",
    "    \"\"\"\n",
    "    forest = []\n",
    "    n_instances = X.shape[0]\n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    # A matrix to store the out-of-bag predictions for each tree (in-bag are left as 'nan')\n",
    "    oob_all_predictions = np.full([n_trees, n_instances], np.nan)\n",
    "    \n",
    "    for i in range(n_trees):\n",
    "        bag_ids = np.random.choice(n_instances, n_instances, replace=True)\n",
    "        tree = DecisionTreeClassifier(**kwargs).fit(X[bag_ids], Y[bag_ids])\n",
    "        \n",
    "        # Save predictions for out-of-bag instances\n",
    "        oob_ids = np.setdiff1d(np.arange(n_instances), bag_ids)\n",
    "        oob_all_predictions[i,oob_ids] = tree.predict(X[oob_ids])\n",
    "        \n",
    "        forest.append(tree) \n",
    "    \n",
    "    # Compute the out-of-bag accuracy (majority vote)\n",
    "    from scipy.stats import mode\n",
    "    oob_vote_prediction = mode(oob_all_predictions, axis=0, nan_policy='omit')[0].flatten()\n",
    "    oob_score = (oob_vote_prediction==Y).mean()\n",
    "    \n",
    "    return {'forest': forest, 'oob_score': oob_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply this function to fit a Random Forest of 100 trees to the Bank Marketing data. \n",
    "Note that a larger forest is generally better, but performance will diminish beyond a certain size.\n",
    "By setting `max_features='sqrt'`, we're restricting each split to a random subset of features of size $\\sqrt{\\mathrm{num\\ features}}$ (i.e. a subset of 8 features for this data).\n",
    "\n",
    "We also print out the out-of-bag accuracy, which we computed while fitting the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-bag accuracy is 0.904\n"
     ]
    }
   ],
   "source": [
    "forest = fit_forest(X_train, Y_train, 100, max_features='sqrt')\n",
    "print('Out-of-bag accuracy is {:.3g}'.format(forest['oob_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now implement a function to make predictions on instances `X` using the forest we've just trained. \n",
    "Remember that for classification, a prediction is made by majority vote among trees in the forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_forest(X, forest):\n",
    "    \"\"\"\n",
    "    Make predictions using majority voting over the trees in the forest\n",
    "    \n",
    "    Arguments\n",
    "    =========\n",
    "    X : numpy array, shape: (n_instances, n_features)\n",
    "        feature matrix\n",
    "    forest : a list of DecisionTreeClassifier instances\n",
    "    \"\"\"\n",
    "    # Allocate array to store predictions for each instance/tree\n",
    "    n_instances = X.shape[0]\n",
    "    n_trees = len(forest)\n",
    "    predictions = np.empty([n_trees, n_instances], dtype=int)\n",
    "    \n",
    "    # Fill array\n",
    "    for (i,tree) in enumerate(forest):\n",
    "        predictions[i] = tree.predict(X)\n",
    "    \n",
    "    # Use majority vote (mode) for each instance\n",
    "    from scipy.stats import mode\n",
    "    return mode(predictions, axis=0)[0].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `predict_forest` function to compute the accuracy on the test set. \n",
    "You should compare the test accuracy to the out-of-bag accuracy computed previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is 0.908\n"
     ]
    }
   ],
   "source": [
    "Y_test_pred = predict_forest(X_test, forest['forest'])\n",
    "test_acc = accuracy_score(Y_test, Y_test_pred)\n",
    "print('The test accuracy is {:.3g}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest in sklearn\n",
    "Let's take a look at the Random Forest implementation available in `sklearn`.\n",
    "Since the underlying algorithm is the same, you should get very similar results (excluding variance due to randomisation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(oob_score=True, n_estimators=100).fit(X_train, Y_train)\n",
    "print('Out-of-bag accuracy is {:.3g}'.format(clf_rf.oob_score_))\n",
    "print('The test accuracy is {:.3g}'.format(clf_rf.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sklearn` implementation includes additional functionality. For example:\n",
    "* it supports training trees in parallel\n",
    "* it can return information about the importance of each feature\n",
    "* it can compute class probabilities\n",
    "\n",
    "Below we plot the relative importance of each feature.\n",
    "\n",
    "**Question:** Does the feature importance make intuitive sense? Remember, we're trying to predict whether a customer will sign up for a term deposit after receiving a call from a telemarketer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = clf_rf.predict(X_test)\n",
    "fig, ax = plt.subplots(figsize=[15,5])\n",
    "ax.bar(df_transformed.columns, clf_rf.feature_importances_)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Relative importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For imbalanced classification problems, accuracy can be a misleading metric.\n",
    "Below we compute the area-under-curve (AUC).\n",
    "If we really care about identifying customers who'll sign up, then precision/recall would be appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thrseshold = roc_curve(Y_test, clf_rf.predict_proba(X_test)[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('ROC curve')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %.3g' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gradient tree boosting\n",
    "In this section, we'll test out another ensemble learning algorithm called _gradient tree boosting_.\n",
    "Like AdaBoost (presented in lectures), gradient tree boosting involves sequentially training an ensemble of weak learners.\n",
    "However, unlike AdaBoost, it allows for the optimisation of an arbitrary differentiable loss function—not only the exponential loss.\n",
    "`sklearn.ensembles.GradientBoostingClassifier` implements gradient tree boosting for the logistic loss as well as the exponential loss (AdaBoost).\n",
    "\n",
    "Unlike Random Forests, gradient tree boosting is prone to overfitting.\n",
    "Ideally, one should tune the parameters (including the maximum tree depth and the number of trees) using cross validation.\n",
    "Below we perform a grid search over the maximum tree depth `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(GradientBoostingClassifier(), param_grid = {'max_depth': [3, 5, 8]})\n",
    "grid.fit(X_train, Y_train)\n",
    "print('Best parameter(s) are {0.best_params_} with score {0.best_score_:.4g}'.format(grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now re-run training using the best parameters without cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gb = GradientBoostingClassifier(**grid.best_params_).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy on the test set below.\n",
    "You should compare the performance of gradient tree boosting with the Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = ... # fill in\n",
    "print('Test accuracy is {:.3g}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `GradientBoostingClassifier` also computes the feature importance.\n",
    "How does the feature importance compare with the `RandomForestClassifier`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15,5])\n",
    "ax.bar(df_transformed.columns, clf_gb.feature_importances_)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how does the ROC curve/AUC compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(Y_test, clf_gb.predict_proba(X_test)[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('ROC curve')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.3g' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
